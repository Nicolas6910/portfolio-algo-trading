{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8163e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Statistiques globales</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:150px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>nb_total_trades</th>\n",
       "      <th>global_volume</th>\n",
       "      <th>global_pnl</th>\n",
       "      <th>global_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3398</td>\n",
       "      <td>7.395438e+06</td>\n",
       "      <td>7562.206903</td>\n",
       "      <td>1337.904184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>RÃ©cap par instrument</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:300px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>instrument_name</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>total_pnl</th>\n",
       "      <th>total_fees</th>\n",
       "      <th>winning_trades</th>\n",
       "      <th>losing_trades</th>\n",
       "      <th>biggest_gain</th>\n",
       "      <th>biggest_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AAVE-PERP</td>\n",
       "      <td>3.578387e+05</td>\n",
       "      <td>1108.599625</td>\n",
       "      <td>51.370833</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>314.007081</td>\n",
       "      <td>-147.457084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ARB-PERP</td>\n",
       "      <td>9.544196e+04</td>\n",
       "      <td>1340.867342</td>\n",
       "      <td>14.855634</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>206.089507</td>\n",
       "      <td>-197.240276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVAX-PERP</td>\n",
       "      <td>1.839627e+05</td>\n",
       "      <td>-26.083140</td>\n",
       "      <td>30.935663</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>362.220936</td>\n",
       "      <td>-457.916586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BNB-PERP</td>\n",
       "      <td>9.242022e+05</td>\n",
       "      <td>4739.758098</td>\n",
       "      <td>169.784812</td>\n",
       "      <td>202</td>\n",
       "      <td>69</td>\n",
       "      <td>193.473909</td>\n",
       "      <td>-76.639391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>2.708471e+05</td>\n",
       "      <td>2127.440668</td>\n",
       "      <td>36.495011</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>476.714044</td>\n",
       "      <td>-383.369547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LINK-PERP</td>\n",
       "      <td>2.839632e+05</td>\n",
       "      <td>-5703.194176</td>\n",
       "      <td>50.227836</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>176.319300</td>\n",
       "      <td>-586.578641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NEAR-PERP</td>\n",
       "      <td>7.350874e+04</td>\n",
       "      <td>442.114576</td>\n",
       "      <td>9.569894</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>265.551910</td>\n",
       "      <td>-303.290088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OP-PERP</td>\n",
       "      <td>4.019350e+05</td>\n",
       "      <td>-1444.462718</td>\n",
       "      <td>74.035595</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>122.941988</td>\n",
       "      <td>-136.718674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PEPE-PERP</td>\n",
       "      <td>5.294870e+04</td>\n",
       "      <td>-3942.772504</td>\n",
       "      <td>3.987885</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-632.297782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SUI-PERP</td>\n",
       "      <td>3.203798e+05</td>\n",
       "      <td>3020.366650</td>\n",
       "      <td>59.902397</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>211.288733</td>\n",
       "      <td>-313.049435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAO-PERP</td>\n",
       "      <td>1.696478e+05</td>\n",
       "      <td>-1207.119465</td>\n",
       "      <td>28.730986</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>71.437321</td>\n",
       "      <td>-135.844967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TIA-PERP</td>\n",
       "      <td>1.565984e+05</td>\n",
       "      <td>-162.441724</td>\n",
       "      <td>23.335427</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>184.422698</td>\n",
       "      <td>-232.836132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TRUMP-PERP</td>\n",
       "      <td>2.613893e+05</td>\n",
       "      <td>83.493936</td>\n",
       "      <td>49.785366</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>172.656943</td>\n",
       "      <td>-101.074612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>1.452921e+05</td>\n",
       "      <td>-842.253325</td>\n",
       "      <td>23.116415</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>118.959085</td>\n",
       "      <td>-950.651535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WIF-PERP</td>\n",
       "      <td>3.091745e+06</td>\n",
       "      <td>-497.052235</td>\n",
       "      <td>611.478990</td>\n",
       "      <td>279</td>\n",
       "      <td>338</td>\n",
       "      <td>191.113055</td>\n",
       "      <td>-175.122125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WLD-PERP</td>\n",
       "      <td>2.539866e+05</td>\n",
       "      <td>3625.699086</td>\n",
       "      <td>46.723255</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>270.845946</td>\n",
       "      <td>-277.312029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XRP-PERP</td>\n",
       "      <td>3.517501e+05</td>\n",
       "      <td>4899.246209</td>\n",
       "      <td>53.568187</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>285.460475</td>\n",
       "      <td>-100.946562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Top 5 plus gros gains (trades individuels)</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:200px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>trade_id</th>\n",
       "      <th>instrument_name</th>\n",
       "      <th>realized_pnl</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>trade_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1fac9f0c-132c-4d18-886a-1cdbbad3bc24</td>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>476.714044</td>\n",
       "      <td>0.42964</td>\n",
       "      <td>11842.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a60b206e-93e8-4371-92c3-fbac8354728b</td>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>417.096732</td>\n",
       "      <td>0.41494</td>\n",
       "      <td>12262.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>09458d79-b460-4862-b6c9-43839eb3e399</td>\n",
       "      <td>AVAX-PERP</td>\n",
       "      <td>362.220936</td>\n",
       "      <td>22.77590</td>\n",
       "      <td>126.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28007f00-89e8-443f-8cb9-8a17fd4298d3</td>\n",
       "      <td>AVAX-PERP</td>\n",
       "      <td>362.192371</td>\n",
       "      <td>22.77590</td>\n",
       "      <td>126.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960cf8dc-8eab-4e15-9091-723d3322916d</td>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>345.653916</td>\n",
       "      <td>0.41549</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Top 5 plus grosses pertes (trades individuels)</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:200px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>trade_id</th>\n",
       "      <th>instrument_name</th>\n",
       "      <th>realized_pnl</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>trade_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0657564e-fa4c-4777-941a-861941ed5b54</td>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>-950.651535</td>\n",
       "      <td>5.918900</td>\n",
       "      <td>8.596100e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>db446007-4441-4b10-af4e-c1152b03e341</td>\n",
       "      <td>PEPE-PERP</td>\n",
       "      <td>-632.297782</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.744400e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a9f8f3d9-df2c-43fe-8351-ea7bbab24300</td>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>-592.547303</td>\n",
       "      <td>5.831400</td>\n",
       "      <td>4.960300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29511f57-586f-4fba-abf1-262c3626f3f0</td>\n",
       "      <td>LINK-PERP</td>\n",
       "      <td>-586.578641</td>\n",
       "      <td>13.304300</td>\n",
       "      <td>3.824320e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73a61568-d0e6-42f2-8943-c332f3d32939</td>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>-507.838913</td>\n",
       "      <td>5.975300</td>\n",
       "      <td>4.833300e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def display_html_table(df, max_height=300):\n",
    "    \"\"\"\n",
    "    Retourne un bloc HTML avec une barre de dÃ©filement verticale (max_height).\n",
    "    \"\"\"\n",
    "    html_str = f\"\"\"\n",
    "    <div style=\"width:100%; max-height:{max_height}px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
    "        {df.to_html(index=False, justify='left')}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return HTML(html_str)\n",
    "\n",
    "\n",
    "def analyze_trades(csv_file_path):\n",
    "    # 1) Lecture du CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # VÃ©rifie que les colonnes existent (ajuste selon tes noms de colonnes)\n",
    "    # On part sur: 'instrument_name', 'trade_price', 'trade_amount', 'trade_fee', 'realized_pnl'\n",
    "    required_cols = ['instrument_name','trade_price','trade_amount','trade_fee','realized_pnl']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"La colonne '{col}' est absente du CSV !\")\n",
    "\n",
    "    # 2) Ajout d'une colonne \"notional\" = trade_price * trade_amount\n",
    "    df['notional'] = df['trade_price'] * df['trade_amount']\n",
    "\n",
    "    # 3) Groupby par instrument_name : calcul des stats\n",
    "    grouped = df.groupby('instrument_name').agg(\n",
    "        total_volume   = pd.NamedAgg(column='notional',       aggfunc='sum'),\n",
    "        total_pnl      = pd.NamedAgg(column='realized_pnl',   aggfunc='sum'),\n",
    "        total_fees     = pd.NamedAgg(column='trade_fee',      aggfunc='sum'),\n",
    "        winning_trades = pd.NamedAgg(column='realized_pnl',   aggfunc=lambda s: (s > 0).sum()),\n",
    "        losing_trades  = pd.NamedAgg(column='realized_pnl',   aggfunc=lambda s: (s < 0).sum()),\n",
    "        biggest_gain   = pd.NamedAgg(column='realized_pnl',   aggfunc='max'),\n",
    "        biggest_loss   = pd.NamedAgg(column='realized_pnl',   aggfunc='min'),\n",
    "    ).reset_index()\n",
    "\n",
    "    # 4) Statistiques globales\n",
    "    global_stats = {\n",
    "        'nb_total_trades': len(df),\n",
    "        'global_volume': df['notional'].sum(),\n",
    "        'global_pnl': df['realized_pnl'].sum(),\n",
    "        'global_fees': df['trade_fee'].sum()\n",
    "    }\n",
    "    global_stats_df = pd.DataFrame([global_stats])\n",
    "\n",
    "    # 5) Top 5 plus gros gains / plus grosses pertes (au niveau des trades individuels)\n",
    "    top_gains = df.nlargest(5, 'realized_pnl')\n",
    "    top_losses = df.nsmallest(5, 'realized_pnl')\n",
    "\n",
    "    # ---- AFFICHAGE HTML ----\n",
    "    # A) Statistiques globales\n",
    "    display(HTML(\"<h2>Statistiques globales</h2>\"))\n",
    "    display(display_html_table(global_stats_df, max_height=150))\n",
    "    \n",
    "    # B) RÃ©sumÃ© par instrument\n",
    "    display(HTML(\"<h2>RÃ©cap par instrument</h2>\"))\n",
    "    display(display_html_table(grouped))\n",
    "    \n",
    "    # C) Top 5 plus gros gains\n",
    "    display(HTML(\"<h2>Top 5 plus gros gains (trades individuels)</h2>\"))\n",
    "    display(display_html_table(top_gains[['trade_id','instrument_name','realized_pnl','trade_price','trade_amount']], max_height=200))\n",
    "    \n",
    "    # D) Top 5 plus grosses pertes\n",
    "    display(HTML(\"<h2>Top 5 plus grosses pertes (trades individuels)</h2>\"))\n",
    "    display(display_html_table(top_losses[['trade_id','instrument_name','realized_pnl','trade_price','trade_amount']], max_height=200))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Exemple d'utilisation (Notebook/Jupyter) :\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = r\"C:\\Users\\nicol\\Desktop\\Algotrading_2025\\DERIVE.XYZ\\extraction_trades2\\PERPS-ALT_1741737600000_1744156800000\\trades_76Fb9.csv\"\n",
    "    analyze_trades(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "WashâTrading Detector â ConsoleâOnly (2025â06)\n",
    "==============================================\n",
    "\n",
    "â¢ Parcourt tous les sousâdossiers de `EXTRACTION_ROOT` dont le nom suit\n",
    "  `PERPS-(ALT|MAJ)_<epochStart>_<epochEnd>` (ignore `OPTIONS-*`).\n",
    "â¢ Charge les adresses MarketâMakers (MM) depuis le JSON fourni.\n",
    "â¢ Construit un graphe makerâtaker, dÃ©tecteÂ :\n",
    "    â cycles courtsÂ (â¤3 nÅuds)Â ;\n",
    "    â Ã©changes bidirectionnels rapprochÃ©s (<â¯1â¯h)Â ;\n",
    "    â adresses Ã  ratio bidirectionnelâ¯>â¯0,5.\n",
    "â¢ Affiche :\n",
    "    â pour chaque programme â 3 tableaux (cycles, bidirectionnels, ratios) +\n",
    "      un tableau rÃ©capitulatif par adresse suspecte + miniârapport par adresse ;\n",
    "    â enfin une synthÃ¨se globale (tous programmes).\n",
    "\n",
    "Aucun fichier nâest Ã©crit. Tout est dans la console â idÃ©al pour CI/log.\n",
    "\n",
    "ExÃ©cutionÂ :\n",
    "    python wash_trading_console.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "###############################################################################\n",
    "# CONFIG UTILISATEUR                                                          #\n",
    "###############################################################################\n",
    "EXTRACTION_ROOT = r\"C:/Users/nicol/Desktop/Algotrading_2025/DERIVE.XYZ/extraction_trades\"\n",
    "MM_JSON_PATH    = r\"C:/Users/nicol/Desktop/Algotrading_2025/DERIVE.XYZ/market_maker_data/all_mm_addresses_by_program.json\"\n",
    "API_URL         = \"https://api.lyra.finance/public/get_trade_history\"\n",
    "\n",
    "PAIRS_BY_PROGRAM: Dict[str, List[str]] = {\n",
    "    \"PERPS-ALT\": [\n",
    "        \"NEAR-PERP\", \"TAO-PERP\", \"SUI-PERP\", \"LINK-PERP\", \"XRP-PERP\", \"ARB-PERP\",\n",
    "        \"WLD-PERP\", \"DEGEN-PERP\", \"SEI-PERP\", \"TIA-PERP\", \"AAVE-PERP\", \"OP-PERP\",\n",
    "        \"BNB-PERP\", \"UNI-PERP\", \"AVAX-PERP\", \"EIGEN-PERP\", \"ENA-PERP\", \"PEPE-PERP\",\n",
    "        \"BITCOIN-PERP\", \"WIF-PERP\", \"TRUMP-PERP\",\n",
    "    ],\n",
    "    \"PERPS-MAJ\": [\"ETH-PERP\", \"SOL-PERP\", \"BTC-PERP\"],\n",
    "}\n",
    "\n",
    "TIME_THRESHOLD = 3600  # secondes (1â¯h) pour la fenÃªtre bidirectionnelle\n",
    "TOP_N_PATTERN  = 10    # lignes Ã  afficher pour chaque tableau\n",
    "TOP_N_ADDRESS  = 10    # adresses Ã  dÃ©tailler\n",
    "###############################################################################\n",
    "# OUTILS DâAFFICHAGE                                                          #\n",
    "###############################################################################\n",
    "\n",
    "def print_df(df: pd.DataFrame, title: str):\n",
    "    \"\"\"Imprime un DataFrame joliment formatÃ© ou âaucun rÃ©sultatâ.\"\"\"\n",
    "    print(f\"\\n{title} (n={len(df)})\" + (\"\" if not df.empty else \" â aucun rÃ©sultat\"))\n",
    "    if not df.empty:\n",
    "        with pd.option_context(\"display.max_columns\", None, \"display.width\", 0):\n",
    "            print(df.to_string(index=False))\n",
    "\n",
    "###############################################################################\n",
    "# 1. DÃTECTION DES SCHÃMAS                                                   #\n",
    "###############################################################################\n",
    "\n",
    "def detect_patterns(G: nx.DiGraph, window: int = TIME_THRESHOLD):\n",
    "    patterns: List[dict] = []\n",
    "\n",
    "    # ---- cycles courts --------------------------------------------------\n",
    "    raw_cycles = [c for c in nx.simple_cycles(G) if len(c) <= 3]\n",
    "    uniq_cycles = {tuple(c[c.index(min(c)):]+c[:c.index(min(c))]) for c in raw_cycles}\n",
    "    for cyc in uniq_cycles:\n",
    "        vol = sum(G[cyc[i]][cyc[(i+1)%len(cyc)]].get(\"volume\", 0) for i in range(len(cyc)))\n",
    "        trades = [t for i in range(len(cyc)) for t in G[cyc[i]][cyc[(i+1)%len(cyc)]].get(\"trades\", [])]\n",
    "        patterns.append({\"type\": \"cycle\", \"addresses\": cyc, \"volume\": vol, \"trades\": trades})\n",
    "\n",
    "    # ---- bidirectionnels rapprochÃ©s -------------------------------------\n",
    "    visited = set()\n",
    "    for u, v in G.edges():\n",
    "        pair = tuple(sorted((u, v)))\n",
    "        if pair in visited or not G.has_edge(v, u):\n",
    "            continue\n",
    "        visited.add(pair)\n",
    "        close_pairs = []\n",
    "        for t1 in G[u][v][\"trades\"]:\n",
    "            for t2 in G[v][u][\"trades\"]:\n",
    "                if t1[\"timestamp\"] and t2[\"timestamp\"]:\n",
    "                    delta = abs((t1[\"timestamp\"] - t2[\"timestamp\"]).total_seconds())\n",
    "                    if delta < window:\n",
    "                        close_pairs.append({\"fwd\": t1, \"bwd\": t2, \"dt\": delta})\n",
    "        if close_pairs:\n",
    "            tot_vol = G[u][v][\"volume\"] + G[v][u][\"volume\"]\n",
    "            patterns.append({\"type\": \"bidi\", \"addresses\": pair, \"volume\": tot_vol, \"pairs\": close_pairs})\n",
    "\n",
    "    # ---- ratios Ã©levÃ©s ---------------------------------------------------\n",
    "    for n in G.nodes():\n",
    "        preds, succs = set(G.predecessors(n)), set(G.successors(n))\n",
    "        all_neigh = preds | succs\n",
    "        if all_neigh:\n",
    "            ratio = len(preds & succs) / len(all_neigh)\n",
    "            if ratio > 0.5 and len(all_neigh) > 1:\n",
    "                patterns.append({\"type\": \"ratio\", \"address\": n, \"ratio\": ratio, \"neighbors\": list(preds & succs)})\n",
    "\n",
    "    return sorted(patterns, key=lambda p: p.get(\"volume\", 0), reverse=True)\n",
    "\n",
    "###############################################################################\n",
    "# 2. GRAPHE DE TRANSACTIONS                                                  #\n",
    "###############################################################################\n",
    "\n",
    "def build_graph(df_maker: pd.DataFrame, df_taker: pd.DataFrame, mm_set: set[str]):\n",
    "    G = nx.DiGraph()\n",
    "    edge_acc: Dict[Tuple[str, str], dict] = defaultdict(lambda: {\"count\": 0, \"volume\": 0.0, \"trades\": []})\n",
    "\n",
    "    maker_map = {r.trade_id: r for r in df_maker.itertuples(index=False)}\n",
    "    for r in df_maker.itertuples(index=False):\n",
    "        G.add_node(r.wallet, trades=G.nodes.get(r.wallet, {}).get(\"trades\", 0)+1, is_mm=r.wallet in mm_set)\n",
    "\n",
    "    for r in df_taker.itertuples(index=False):\n",
    "        if r.trade_id not in maker_map:\n",
    "            continue\n",
    "        m_wallet, t_wallet = maker_map[r.trade_id].wallet, r.wallet\n",
    "        for w in (t_wallet,):\n",
    "            G.add_node(w, trades=G.nodes.get(w, {}).get(\"trades\", 0)+1, is_mm=w in mm_set)\n",
    "        vol = getattr(r, \"volume_usdt\", 0.0)\n",
    "        meta = edge_acc[(m_wallet, t_wallet)]\n",
    "        meta[\"count\"] += 1\n",
    "        meta[\"volume\"] += vol\n",
    "        meta[\"trades\"].append({\"trade_id\": r.trade_id, \"timestamp\": getattr(r, \"datetime\", None), \"volume\": vol})\n",
    "\n",
    "    for (u, v), d in edge_acc.items():\n",
    "        G.add_edge(u, v, **d)\n",
    "    return G\n",
    "\n",
    "###############################################################################\n",
    "# 3. CHARGEMENT DES DONNÃES                                                  #\n",
    "###############################################################################\n",
    "\n",
    "def _prepare(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    if {\"trade_price\", \"trade_amount\"}.issubset(df.columns):\n",
    "        df[\"volume_usdt\"] = pd.to_numeric(df.trade_price, errors=\"coerce\") * pd.to_numeric(df.trade_amount, errors=\"coerce\")\n",
    "    if \"timestamp\" in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df.timestamp, errors=\"coerce\", unit=\"ms\" if df.timestamp.dtype != object else None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_trades_api(pairs: List[str], ts_from: int, ts_to: int) -> pd.DataFrame:\n",
    "    all_trades = []\n",
    "    max_pages = 10  # limite de sÃ©curitÃ©\n",
    "    max_errors = 3\n",
    "\n",
    "    for pair in tqdm(pairs, desc=\"API\", leave=False):\n",
    "        page = 1\n",
    "        error_count = 0\n",
    "        while page <= max_pages:\n",
    "            payload = {\n",
    "                \"instrument_name\": pair,\n",
    "                \"from_timestamp\": ts_from,\n",
    "                \"to_timestamp\": ts_to,\n",
    "                \"instrument_type\": \"perp\",\n",
    "                \"page\": page,\n",
    "                \"page_size\": 1000,\n",
    "            }\n",
    "            try:\n",
    "                r = requests.post(API_URL, json=payload, timeout=10)\n",
    "                r.raise_for_status()\n",
    "                res = r.json().get(\"result\", {})\n",
    "                trades = res.get(\"trades\", []) if isinstance(res, dict) else res\n",
    "                if not trades:\n",
    "                    break\n",
    "                all_trades.extend(trades)\n",
    "                if len(trades) < 1000:\n",
    "                    break\n",
    "                page += 1\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Erreur API sur {pair} (page {page}) : {str(e)}\")\n",
    "                if error_count >= max_errors:\n",
    "                    print(f\"Abandon de la paire {pair} aprÃ¨s {error_count} erreurs.\")\n",
    "                    break\n",
    "    return _prepare(pd.DataFrame(all_trades))\n",
    "\n",
    "\n",
    "\n",
    "def load_data(csv_files: List[str], pairs: List[str], ts_from: int, ts_to: int):\n",
    "    df_csv = pd.concat([pd.read_csv(p) for p in csv_files], ignore_index=True)\n",
    "    trade_ids = df_csv[df_csv.liquidity_role.str.lower()==\"maker\"].trade_id.unique()\n",
    "\n",
    "    df_api = fetch_trades_api(pairs, ts_from, ts_to)\n",
    "    if df_api.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    df_api = df_api[df_api.trade_id.isin(trade_ids)]\n",
    "    return (\n",
    "        _prepare(df_api[df_api.liquidity_role.str.lower()==\"maker\"]),\n",
    "        _prepare(df_api[df_api.liquidity_role.str.lower()==\"taker\"]),\n",
    "    )\n",
    "\n",
    "###############################################################################\n",
    "# 4. ANALYSE DâUN PROGRAMME                                                 #\n",
    "###############################################################################\n",
    "\n",
    "def analyse_program(folder: str, mm_map: Dict[str, List[str]]):\n",
    "    parts = folder.split(\"_\")\n",
    "    if len(parts) != 3:\n",
    "        return None  # format inattendu\n",
    "    program_name, start_ts_str, end_ts_str = parts[0], parts[1], parts[2]\n",
    "    if program_name not in PAIRS_BY_PROGRAM:\n",
    "        return None  # ignore OPTIONS et inconnus\n",
    "\n",
    "    start_ts = int(start_ts_str)\n",
    "    key_mm = f\"{program_name}_{start_ts}\"\n",
    "    mm_list = mm_map.get(key_mm, [])\n",
    "\n",
    "    csv_folder = os.path.join(EXTRACTION_ROOT, folder)\n",
    "    if not os.path.isdir(csv_folder):\n",
    "        return None\n",
    "    csv_files = [os.path.join(csv_folder, f) for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        return None\n",
    "\n",
    "    # Header programme\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    date_str = datetime.fromtimestamp(start_ts/1000).strftime(\"%Y-%m-%d\")\n",
    "    print(f\"PROGRAMME {program_name} | epoch {date_str} | CSV {len(csv_files)} | MM {len(mm_list)}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    df_maker, df_taker = load_data(csv_files, PAIRS_BY_PROGRAM[program_name], start_ts, int(end_ts_str))\n",
    "    if df_maker.empty or df_taker.empty:\n",
    "        print(\"  â aucune donnÃ©e exploitable (API ou CSV)\")\n",
    "        return None\n",
    "\n",
    "    G = build_graph(df_maker, df_taker, set(mm_list))\n",
    "    patterns = detect_patterns(G)\n",
    "\n",
    "    # Tableaux patterns ---------------------------------------------------\n",
    "    cycles = [p for p in patterns if p[\"type\"] == \"cycle\"]\n",
    "    bidis  = [p for p in patterns if p[\"type\"] == \"bidi\"]\n",
    "    ratios = [p for p in patterns if p[\"type\"] == \"ratio\"]\n",
    "\n",
    "    print_df(pd.DataFrame([\n",
    "        {\"ID\": i+1, \"Chemin\": \" -> \".join(p[\"addresses\"]) + \" -> \" + p[\"addresses\"][0], \"Volume\": p[\"volume\"], \"Trades\": len(p[\"trades\"])}\n",
    "        for i, p in enumerate(cycles)\n",
    "    ]).head(TOP_N_PATTERN), \"CYCLES COURTS\")\n",
    "\n",
    "    print_df(pd.DataFrame([\n",
    "        {\"ID\": i+1, \"Adresses\": \" <-> \".join(p[\"addresses\"]), \"Volume\": p[\"volume\"], \"Paires\": len(p[\"pairs\"])}\n",
    "        for i, p in enumerate(bidis)\n",
    "    ]).head(TOP_N_PATTERN), \"BIDIRECTIONNELS <1h\")\n",
    "\n",
    "    print_df(pd.DataFrame([\n",
    "        {\"ID\": i+1, \"Adresse\": p[\"address\"], \"Ratio\": f\"{p['ratio']:.2f}\", \"Voisins\": len(p[\"neighbors\"])}\n",
    "        for i, p in enumerate(ratios)\n",
    "    ]).head(TOP_N_PATTERN), \"ADRESSES RATIO>0.5\")\n",
    "\n",
    "    # RÃ©cap par adresse suspecte -----------------------------------------\n",
    "    addr_stats: Dict[str, dict] = defaultdict(lambda: {\"patterns\": 0, \"volume\": 0.0, \"cycles\": 0, \"bidis\": 0, \"ratios\": 0})\n",
    "    for p in patterns:\n",
    "        if p[\"type\"] == \"cycle\":\n",
    "            for a in p[\"addresses\"]:\n",
    "                s = addr_stats[a]; s[\"patterns\"] += 1; s[\"volume\"] += p[\"volume\"]; s[\"cycles\"] += 1\n",
    "        elif p[\"type\"] == \"bidi\":\n",
    "            for a in p[\"addresses\"]:\n",
    "                s = addr_stats[a]; s[\"patterns\"] += 1; s[\"volume\"] += p[\"volume\"]; s[\"bidis\"] += 1\n",
    "        else:\n",
    "            a = p[\"address\"]\n",
    "            s = addr_stats[a]; s[\"patterns\"] += 1; s[\"ratios\"] += 1\n",
    "\n",
    "    addr_df = pd.DataFrame([\n",
    "        {\"Adresse\": a, **stats} for a, stats in addr_stats.items()\n",
    "    ]).sort_values([\"patterns\", \"volume\"], ascending=False)\n",
    "\n",
    "    print_df(addr_df.head(TOP_N_ADDRESS), \"ADRESSES LES PLUS SUSPECTES\")\n",
    "\n",
    "    # Miniârapport par adresseÂ (affichage dÃ©taillÃ©)\n",
    "    for _, row in addr_df.head(TOP_N_ADDRESS).iterrows():\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"ADRESSE SUSPECTE : {row['Adresse']}\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"  â¢ Patterns totaux     : {row['patterns']}\")\n",
    "        print(f\"  â¢ Volume suspect      : ${row['volume']:,.2f}\")\n",
    "        print(f\"    â Cycles            : {row['cycles']}\")\n",
    "        print(f\"    â Bidirectionnels   : {row['bidis']}\")\n",
    "        print(f\"    â Ratios Ã©levÃ©s     : {row['ratios']}\")\n",
    "\n",
    "    return {\n",
    "        \"program_name\": program_name,\n",
    "        \"date\": date_str,\n",
    "        \"patterns_count\": len(patterns),\n",
    "        \"cycles\": len(cycles),\n",
    "        \"bidis\": len(bidis),\n",
    "        \"ratios\": len(ratios),\n",
    "        \"total_volume\": sum(p.get(\"volume\", 0) for p in patterns),\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 5. BOUCLE GLOBALE                                                          #\n",
    "###############################################################################\n",
    "\n",
    "def run_all_programs():\n",
    "    # VÃ©rifier chemins\n",
    "    if not os.path.isdir(EXTRACTION_ROOT):\n",
    "        raise FileNotFoundError(f\"EXTRACTION_ROOT introuvable: {EXTRACTION_ROOT}\")\n",
    "    if not os.path.isfile(MM_JSON_PATH):\n",
    "        raise FileNotFoundError(f\"MM_JSON_PATH introuvable: {MM_JSON_PATH}\")\n",
    "\n",
    "    with open(MM_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        mm_map = json.load(f)\n",
    "\n",
    "    folders = [d for d in os.listdir(EXTRACTION_ROOT) if os.path.isdir(os.path.join(EXTRACTION_ROOT, d))]\n",
    "    folders.sort()\n",
    "\n",
    "    global_results = []\n",
    "    for folder in folders:\n",
    "        res = analyse_program(folder, mm_map)\n",
    "        if res:\n",
    "            global_results.append(res)\n",
    "\n",
    "    # ------------------------------ SynthÃ¨se globale ---------------------------\n",
    "    if global_results:\n",
    "        total_prog = len(global_results)\n",
    "        tot_patterns = sum(r[\"patterns_count\"] for r in global_results)\n",
    "        tot_cycles   = sum(r[\"cycles\"] for r in global_results)\n",
    "        tot_bidis    = sum(r[\"bidis\"] for r in global_results)\n",
    "        tot_ratios   = sum(r[\"ratios\"] for r in global_results)\n",
    "        tot_volume   = sum(r[\"total_volume\"] for r in global_results)\n",
    "\n",
    "        top_prog = max(global_results, key=lambda r: r[\"patterns_count\"])[\"program_name\"] if global_results else None\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SYNTHÃSE GLOBALE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Programmes analysÃ©s          : {total_prog}\")\n",
    "        print(f\"Patterns suspects (total)    : {tot_patterns}\")\n",
    "        print(f\"Volume total suspect         : ${tot_volume:,.2f}\")\n",
    "        print(\"RÃ©partition des patterns     :\")\n",
    "        print(f\"  â Cycles                  : {tot_cycles}\")\n",
    "        print(f\"  â Bidirectionnels <1h     : {tot_bidis}\")\n",
    "        print(f\"  â Ratios Ã©levÃ©s           : {tot_ratios}\")\n",
    "        if top_prog:\n",
    "            print(f\"\\nProgramme le plus problÃ©matique : {top_prog}\")\n",
    "\n",
    "        # DÃ©tail top 3\n",
    "        df_glob = pd.DataFrame(global_results)\n",
    "        df_top = df_glob.sort_values(\"patterns_count\", ascending=False).head(3)\n",
    "        if not df_top.empty:\n",
    "            print(\"\\nTop 3 programmes par patterns suspects :\")\n",
    "            for i, row in enumerate(df_top.itertuples(index=False), 1):\n",
    "                print(f\"{i}. {row.program_name} ({row.date}) â {row.patterns_count} patterns, volume ${row.total_volume:,.2f}\")\n",
    "\n",
    "        # Recommandations de base\n",
    "        print(\"\\nRECOMMANDATIONS :\")\n",
    "        recos = [\n",
    "            \"Inspecter manuellement les programmes avec >100 patterns et/ou volume Ã©levÃ©\",\n",
    "            \"Identifier si les adresses apparaissent dans plusieurs programmes\",\n",
    "            \"Surveiller en continu les cycles courts rÃ©currents\",\n",
    "            \"Mettre en place seuils dynamiques sur ratio bidirectionnel\",\n",
    "            \"RÃ©viser les conditions d'Ã©ligibilitÃ© des market-makers\",\n",
    "        ]\n",
    "        for i, txt in enumerate(recos, 1):\n",
    "            print(f\"{i}. {txt}\")\n",
    "\n",
    "        print(\"\\nATTENTION : ces heuristiques signalent des anomalies, pas des preuves. Une revue humaine reste indispensable.\")\n",
    "    else:\n",
    "        print(\"\\nAucun programme exploitable n'a Ã©tÃ© trouvÃ© ou aucune donnÃ©e retour API.\")\n",
    "\n",
    "###############################################################################\n",
    "# 6. MAIN                                                                     #\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ANALYSE DE WASH TRADING â VERSION CONSOLE SEULE\")\n",
    "    run_all_programs()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
