{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d8163e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h2>Statistiques globales</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:150px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>nb_total_trades</th>\n",
       "      <th>global_volume</th>\n",
       "      <th>global_pnl</th>\n",
       "      <th>global_fees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>3398</td>\n",
       "      <td>7.395438e+06</td>\n",
       "      <td>7562.206903</td>\n",
       "      <td>1337.904184</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Récap par instrument</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:300px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>instrument_name</th>\n",
       "      <th>total_volume</th>\n",
       "      <th>total_pnl</th>\n",
       "      <th>total_fees</th>\n",
       "      <th>winning_trades</th>\n",
       "      <th>losing_trades</th>\n",
       "      <th>biggest_gain</th>\n",
       "      <th>biggest_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>AAVE-PERP</td>\n",
       "      <td>3.578387e+05</td>\n",
       "      <td>1108.599625</td>\n",
       "      <td>51.370833</td>\n",
       "      <td>41</td>\n",
       "      <td>52</td>\n",
       "      <td>314.007081</td>\n",
       "      <td>-147.457084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ARB-PERP</td>\n",
       "      <td>9.544196e+04</td>\n",
       "      <td>1340.867342</td>\n",
       "      <td>14.855634</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>206.089507</td>\n",
       "      <td>-197.240276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>AVAX-PERP</td>\n",
       "      <td>1.839627e+05</td>\n",
       "      <td>-26.083140</td>\n",
       "      <td>30.935663</td>\n",
       "      <td>17</td>\n",
       "      <td>37</td>\n",
       "      <td>362.220936</td>\n",
       "      <td>-457.916586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>BNB-PERP</td>\n",
       "      <td>9.242022e+05</td>\n",
       "      <td>4739.758098</td>\n",
       "      <td>169.784812</td>\n",
       "      <td>202</td>\n",
       "      <td>69</td>\n",
       "      <td>193.473909</td>\n",
       "      <td>-76.639391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>2.708471e+05</td>\n",
       "      <td>2127.440668</td>\n",
       "      <td>36.495011</td>\n",
       "      <td>70</td>\n",
       "      <td>65</td>\n",
       "      <td>476.714044</td>\n",
       "      <td>-383.369547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>LINK-PERP</td>\n",
       "      <td>2.839632e+05</td>\n",
       "      <td>-5703.194176</td>\n",
       "      <td>50.227836</td>\n",
       "      <td>11</td>\n",
       "      <td>83</td>\n",
       "      <td>176.319300</td>\n",
       "      <td>-586.578641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>NEAR-PERP</td>\n",
       "      <td>7.350874e+04</td>\n",
       "      <td>442.114576</td>\n",
       "      <td>9.569894</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>265.551910</td>\n",
       "      <td>-303.290088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>OP-PERP</td>\n",
       "      <td>4.019350e+05</td>\n",
       "      <td>-1444.462718</td>\n",
       "      <td>74.035595</td>\n",
       "      <td>28</td>\n",
       "      <td>53</td>\n",
       "      <td>122.941988</td>\n",
       "      <td>-136.718674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PEPE-PERP</td>\n",
       "      <td>5.294870e+04</td>\n",
       "      <td>-3942.772504</td>\n",
       "      <td>3.987885</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-632.297782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>SUI-PERP</td>\n",
       "      <td>3.203798e+05</td>\n",
       "      <td>3020.366650</td>\n",
       "      <td>59.902397</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>211.288733</td>\n",
       "      <td>-313.049435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TAO-PERP</td>\n",
       "      <td>1.696478e+05</td>\n",
       "      <td>-1207.119465</td>\n",
       "      <td>28.730986</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>71.437321</td>\n",
       "      <td>-135.844967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TIA-PERP</td>\n",
       "      <td>1.565984e+05</td>\n",
       "      <td>-162.441724</td>\n",
       "      <td>23.335427</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>184.422698</td>\n",
       "      <td>-232.836132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>TRUMP-PERP</td>\n",
       "      <td>2.613893e+05</td>\n",
       "      <td>83.493936</td>\n",
       "      <td>49.785366</td>\n",
       "      <td>65</td>\n",
       "      <td>69</td>\n",
       "      <td>172.656943</td>\n",
       "      <td>-101.074612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>1.452921e+05</td>\n",
       "      <td>-842.253325</td>\n",
       "      <td>23.116415</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>118.959085</td>\n",
       "      <td>-950.651535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WIF-PERP</td>\n",
       "      <td>3.091745e+06</td>\n",
       "      <td>-497.052235</td>\n",
       "      <td>611.478990</td>\n",
       "      <td>279</td>\n",
       "      <td>338</td>\n",
       "      <td>191.113055</td>\n",
       "      <td>-175.122125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>WLD-PERP</td>\n",
       "      <td>2.539866e+05</td>\n",
       "      <td>3625.699086</td>\n",
       "      <td>46.723255</td>\n",
       "      <td>30</td>\n",
       "      <td>13</td>\n",
       "      <td>270.845946</td>\n",
       "      <td>-277.312029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XRP-PERP</td>\n",
       "      <td>3.517501e+05</td>\n",
       "      <td>4899.246209</td>\n",
       "      <td>53.568187</td>\n",
       "      <td>82</td>\n",
       "      <td>7</td>\n",
       "      <td>285.460475</td>\n",
       "      <td>-100.946562</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Top 5 plus gros gains (trades individuels)</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:200px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>trade_id</th>\n",
       "      <th>instrument_name</th>\n",
       "      <th>realized_pnl</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>trade_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1fac9f0c-132c-4d18-886a-1cdbbad3bc24</td>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>476.714044</td>\n",
       "      <td>0.42964</td>\n",
       "      <td>11842.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a60b206e-93e8-4371-92c3-fbac8354728b</td>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>417.096732</td>\n",
       "      <td>0.41494</td>\n",
       "      <td>12262.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>09458d79-b460-4862-b6c9-43839eb3e399</td>\n",
       "      <td>AVAX-PERP</td>\n",
       "      <td>362.220936</td>\n",
       "      <td>22.77590</td>\n",
       "      <td>126.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28007f00-89e8-443f-8cb9-8a17fd4298d3</td>\n",
       "      <td>AVAX-PERP</td>\n",
       "      <td>362.192371</td>\n",
       "      <td>22.77590</td>\n",
       "      <td>126.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>960cf8dc-8eab-4e15-9091-723d3322916d</td>\n",
       "      <td>ENA-PERP</td>\n",
       "      <td>345.653916</td>\n",
       "      <td>0.41549</td>\n",
       "      <td>10000.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<h2>Top 5 plus grosses pertes (trades individuels)</h2>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div style=\"width:100%; max-height:200px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
       "        <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>trade_id</th>\n",
       "      <th>instrument_name</th>\n",
       "      <th>realized_pnl</th>\n",
       "      <th>trade_price</th>\n",
       "      <th>trade_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0657564e-fa4c-4777-941a-861941ed5b54</td>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>-950.651535</td>\n",
       "      <td>5.918900</td>\n",
       "      <td>8.596100e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>db446007-4441-4b10-af4e-c1152b03e341</td>\n",
       "      <td>PEPE-PERP</td>\n",
       "      <td>-632.297782</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>6.744400e+08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>a9f8f3d9-df2c-43fe-8351-ea7bbab24300</td>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>-592.547303</td>\n",
       "      <td>5.831400</td>\n",
       "      <td>4.960300e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29511f57-586f-4fba-abf1-262c3626f3f0</td>\n",
       "      <td>LINK-PERP</td>\n",
       "      <td>-586.578641</td>\n",
       "      <td>13.304300</td>\n",
       "      <td>3.824320e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73a61568-d0e6-42f2-8943-c332f3d32939</td>\n",
       "      <td>UNI-PERP</td>\n",
       "      <td>-507.838913</td>\n",
       "      <td>5.975300</td>\n",
       "      <td>4.833300e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import HTML, display\n",
    "\n",
    "def display_html_table(df, max_height=300):\n",
    "    \"\"\"\n",
    "    Retourne un bloc HTML avec une barre de défilement verticale (max_height).\n",
    "    \"\"\"\n",
    "    html_str = f\"\"\"\n",
    "    <div style=\"width:100%; max-height:{max_height}px; overflow:auto; border:1px solid #666; margin-bottom:10px;\">\n",
    "        {df.to_html(index=False, justify='left')}\n",
    "    </div>\n",
    "    \"\"\"\n",
    "    return HTML(html_str)\n",
    "\n",
    "\n",
    "def analyze_trades(csv_file_path):\n",
    "    # 1) Lecture du CSV\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "    \n",
    "    # Vérifie que les colonnes existent (ajuste selon tes noms de colonnes)\n",
    "    # On part sur: 'instrument_name', 'trade_price', 'trade_amount', 'trade_fee', 'realized_pnl'\n",
    "    required_cols = ['instrument_name','trade_price','trade_amount','trade_fee','realized_pnl']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"La colonne '{col}' est absente du CSV !\")\n",
    "\n",
    "    # 2) Ajout d'une colonne \"notional\" = trade_price * trade_amount\n",
    "    df['notional'] = df['trade_price'] * df['trade_amount']\n",
    "\n",
    "    # 3) Groupby par instrument_name : calcul des stats\n",
    "    grouped = df.groupby('instrument_name').agg(\n",
    "        total_volume   = pd.NamedAgg(column='notional',       aggfunc='sum'),\n",
    "        total_pnl      = pd.NamedAgg(column='realized_pnl',   aggfunc='sum'),\n",
    "        total_fees     = pd.NamedAgg(column='trade_fee',      aggfunc='sum'),\n",
    "        winning_trades = pd.NamedAgg(column='realized_pnl',   aggfunc=lambda s: (s > 0).sum()),\n",
    "        losing_trades  = pd.NamedAgg(column='realized_pnl',   aggfunc=lambda s: (s < 0).sum()),\n",
    "        biggest_gain   = pd.NamedAgg(column='realized_pnl',   aggfunc='max'),\n",
    "        biggest_loss   = pd.NamedAgg(column='realized_pnl',   aggfunc='min'),\n",
    "    ).reset_index()\n",
    "\n",
    "    # 4) Statistiques globales\n",
    "    global_stats = {\n",
    "        'nb_total_trades': len(df),\n",
    "        'global_volume': df['notional'].sum(),\n",
    "        'global_pnl': df['realized_pnl'].sum(),\n",
    "        'global_fees': df['trade_fee'].sum()\n",
    "    }\n",
    "    global_stats_df = pd.DataFrame([global_stats])\n",
    "\n",
    "    # 5) Top 5 plus gros gains / plus grosses pertes (au niveau des trades individuels)\n",
    "    top_gains = df.nlargest(5, 'realized_pnl')\n",
    "    top_losses = df.nsmallest(5, 'realized_pnl')\n",
    "\n",
    "    # ---- AFFICHAGE HTML ----\n",
    "    # A) Statistiques globales\n",
    "    display(HTML(\"<h2>Statistiques globales</h2>\"))\n",
    "    display(display_html_table(global_stats_df, max_height=150))\n",
    "    \n",
    "    # B) Résumé par instrument\n",
    "    display(HTML(\"<h2>Récap par instrument</h2>\"))\n",
    "    display(display_html_table(grouped))\n",
    "    \n",
    "    # C) Top 5 plus gros gains\n",
    "    display(HTML(\"<h2>Top 5 plus gros gains (trades individuels)</h2>\"))\n",
    "    display(display_html_table(top_gains[['trade_id','instrument_name','realized_pnl','trade_price','trade_amount']], max_height=200))\n",
    "    \n",
    "    # D) Top 5 plus grosses pertes\n",
    "    display(HTML(\"<h2>Top 5 plus grosses pertes (trades individuels)</h2>\"))\n",
    "    display(display_html_table(top_losses[['trade_id','instrument_name','realized_pnl','trade_price','trade_amount']], max_height=200))\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Exemple d'utilisation (Notebook/Jupyter) :\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = r\"C:\\Users\\nicol\\Desktop\\Algotrading_2025\\DERIVE.XYZ\\extraction_trades2\\PERPS-ALT_1741737600000_1744156800000\\trades_76Fb9.csv\"\n",
    "    analyze_trades(csv_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Wash‑Trading Detector — Console‑Only (2025‑06)\n",
    "==============================================\n",
    "\n",
    "• Parcourt tous les sous‑dossiers de `EXTRACTION_ROOT` dont le nom suit\n",
    "  `PERPS-(ALT|MAJ)_<epochStart>_<epochEnd>` (ignore `OPTIONS-*`).\n",
    "• Charge les adresses Market‑Makers (MM) depuis le JSON fourni.\n",
    "• Construit un graphe maker→taker, détecte :\n",
    "    – cycles courts (≤3 nœuds) ;\n",
    "    – échanges bidirectionnels rapprochés (< 1 h) ;\n",
    "    – adresses à ratio bidirectionnel > 0,5.\n",
    "• Affiche :\n",
    "    – pour chaque programme → 3 tableaux (cycles, bidirectionnels, ratios) +\n",
    "      un tableau récapitulatif par adresse suspecte + mini‑rapport par adresse ;\n",
    "    – enfin une synthèse globale (tous programmes).\n",
    "\n",
    "Aucun fichier n’est écrit. Tout est dans la console → idéal pour CI/log.\n",
    "\n",
    "Exécution :\n",
    "    python wash_trading_console.py\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Dict, List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "\n",
    "###############################################################################\n",
    "# CONFIG UTILISATEUR                                                          #\n",
    "###############################################################################\n",
    "EXTRACTION_ROOT = r\"C:/Users/nicol/Desktop/Algotrading_2025/DERIVE.XYZ/extraction_trades\"\n",
    "MM_JSON_PATH    = r\"C:/Users/nicol/Desktop/Algotrading_2025/DERIVE.XYZ/market_maker_data/all_mm_addresses_by_program.json\"\n",
    "API_URL         = \"https://api.lyra.finance/public/get_trade_history\"\n",
    "\n",
    "PAIRS_BY_PROGRAM: Dict[str, List[str]] = {\n",
    "    \"PERPS-ALT\": [\n",
    "        \"NEAR-PERP\", \"TAO-PERP\", \"SUI-PERP\", \"LINK-PERP\", \"XRP-PERP\", \"ARB-PERP\",\n",
    "        \"WLD-PERP\", \"DEGEN-PERP\", \"SEI-PERP\", \"TIA-PERP\", \"AAVE-PERP\", \"OP-PERP\",\n",
    "        \"BNB-PERP\", \"UNI-PERP\", \"AVAX-PERP\", \"EIGEN-PERP\", \"ENA-PERP\", \"PEPE-PERP\",\n",
    "        \"BITCOIN-PERP\", \"WIF-PERP\", \"TRUMP-PERP\",\n",
    "    ],\n",
    "    \"PERPS-MAJ\": [\"ETH-PERP\", \"SOL-PERP\", \"BTC-PERP\"],\n",
    "}\n",
    "\n",
    "TIME_THRESHOLD = 3600  # secondes (1 h) pour la fenêtre bidirectionnelle\n",
    "TOP_N_PATTERN  = 10    # lignes à afficher pour chaque tableau\n",
    "TOP_N_ADDRESS  = 10    # adresses à détailler\n",
    "###############################################################################\n",
    "# OUTILS D’AFFICHAGE                                                          #\n",
    "###############################################################################\n",
    "\n",
    "def print_df(df: pd.DataFrame, title: str):\n",
    "    \"\"\"Imprime un DataFrame joliment formaté ou ‘aucun résultat’.\"\"\"\n",
    "    print(f\"\\n{title} (n={len(df)})\" + (\"\" if not df.empty else \" — aucun résultat\"))\n",
    "    if not df.empty:\n",
    "        with pd.option_context(\"display.max_columns\", None, \"display.width\", 0):\n",
    "            print(df.to_string(index=False))\n",
    "\n",
    "###############################################################################\n",
    "# 1. DÉTECTION DES SCHÉMAS                                                   #\n",
    "###############################################################################\n",
    "\n",
    "def detect_patterns(G: nx.DiGraph, window: int = TIME_THRESHOLD):\n",
    "    patterns: List[dict] = []\n",
    "\n",
    "    # ---- cycles courts --------------------------------------------------\n",
    "    raw_cycles = [c for c in nx.simple_cycles(G) if len(c) <= 3]\n",
    "    uniq_cycles = {tuple(c[c.index(min(c)):]+c[:c.index(min(c))]) for c in raw_cycles}\n",
    "    for cyc in uniq_cycles:\n",
    "        vol = sum(G[cyc[i]][cyc[(i+1)%len(cyc)]].get(\"volume\", 0) for i in range(len(cyc)))\n",
    "        trades = [t for i in range(len(cyc)) for t in G[cyc[i]][cyc[(i+1)%len(cyc)]].get(\"trades\", [])]\n",
    "        patterns.append({\"type\": \"cycle\", \"addresses\": cyc, \"volume\": vol, \"trades\": trades})\n",
    "\n",
    "    # ---- bidirectionnels rapprochés -------------------------------------\n",
    "    visited = set()\n",
    "    for u, v in G.edges():\n",
    "        pair = tuple(sorted((u, v)))\n",
    "        if pair in visited or not G.has_edge(v, u):\n",
    "            continue\n",
    "        visited.add(pair)\n",
    "        close_pairs = []\n",
    "        for t1 in G[u][v][\"trades\"]:\n",
    "            for t2 in G[v][u][\"trades\"]:\n",
    "                if t1[\"timestamp\"] and t2[\"timestamp\"]:\n",
    "                    delta = abs((t1[\"timestamp\"] - t2[\"timestamp\"]).total_seconds())\n",
    "                    if delta < window:\n",
    "                        close_pairs.append({\"fwd\": t1, \"bwd\": t2, \"dt\": delta})\n",
    "        if close_pairs:\n",
    "            tot_vol = G[u][v][\"volume\"] + G[v][u][\"volume\"]\n",
    "            patterns.append({\"type\": \"bidi\", \"addresses\": pair, \"volume\": tot_vol, \"pairs\": close_pairs})\n",
    "\n",
    "    # ---- ratios élevés ---------------------------------------------------\n",
    "    for n in G.nodes():\n",
    "        preds, succs = set(G.predecessors(n)), set(G.successors(n))\n",
    "        all_neigh = preds | succs\n",
    "        if all_neigh:\n",
    "            ratio = len(preds & succs) / len(all_neigh)\n",
    "            if ratio > 0.5 and len(all_neigh) > 1:\n",
    "                patterns.append({\"type\": \"ratio\", \"address\": n, \"ratio\": ratio, \"neighbors\": list(preds & succs)})\n",
    "\n",
    "    return sorted(patterns, key=lambda p: p.get(\"volume\", 0), reverse=True)\n",
    "\n",
    "###############################################################################\n",
    "# 2. GRAPHE DE TRANSACTIONS                                                  #\n",
    "###############################################################################\n",
    "\n",
    "def build_graph(df_maker: pd.DataFrame, df_taker: pd.DataFrame, mm_set: set[str]):\n",
    "    G = nx.DiGraph()\n",
    "    edge_acc: Dict[Tuple[str, str], dict] = defaultdict(lambda: {\"count\": 0, \"volume\": 0.0, \"trades\": []})\n",
    "\n",
    "    maker_map = {r.trade_id: r for r in df_maker.itertuples(index=False)}\n",
    "    for r in df_maker.itertuples(index=False):\n",
    "        G.add_node(r.wallet, trades=G.nodes.get(r.wallet, {}).get(\"trades\", 0)+1, is_mm=r.wallet in mm_set)\n",
    "\n",
    "    for r in df_taker.itertuples(index=False):\n",
    "        if r.trade_id not in maker_map:\n",
    "            continue\n",
    "        m_wallet, t_wallet = maker_map[r.trade_id].wallet, r.wallet\n",
    "        for w in (t_wallet,):\n",
    "            G.add_node(w, trades=G.nodes.get(w, {}).get(\"trades\", 0)+1, is_mm=w in mm_set)\n",
    "        vol = getattr(r, \"volume_usdt\", 0.0)\n",
    "        meta = edge_acc[(m_wallet, t_wallet)]\n",
    "        meta[\"count\"] += 1\n",
    "        meta[\"volume\"] += vol\n",
    "        meta[\"trades\"].append({\"trade_id\": r.trade_id, \"timestamp\": getattr(r, \"datetime\", None), \"volume\": vol})\n",
    "\n",
    "    for (u, v), d in edge_acc.items():\n",
    "        G.add_edge(u, v, **d)\n",
    "    return G\n",
    "\n",
    "###############################################################################\n",
    "# 3. CHARGEMENT DES DONNÉES                                                  #\n",
    "###############################################################################\n",
    "\n",
    "def _prepare(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    if df.empty:\n",
    "        return df\n",
    "    df = df.copy()\n",
    "    if {\"trade_price\", \"trade_amount\"}.issubset(df.columns):\n",
    "        df[\"volume_usdt\"] = pd.to_numeric(df.trade_price, errors=\"coerce\") * pd.to_numeric(df.trade_amount, errors=\"coerce\")\n",
    "    if \"timestamp\" in df.columns:\n",
    "        df[\"datetime\"] = pd.to_datetime(df.timestamp, errors=\"coerce\", unit=\"ms\" if df.timestamp.dtype != object else None)\n",
    "    return df\n",
    "\n",
    "\n",
    "def fetch_trades_api(pairs: List[str], ts_from: int, ts_to: int) -> pd.DataFrame:\n",
    "    all_trades = []\n",
    "    max_pages = 10  # limite de sécurité\n",
    "    max_errors = 3\n",
    "\n",
    "    for pair in tqdm(pairs, desc=\"API\", leave=False):\n",
    "        page = 1\n",
    "        error_count = 0\n",
    "        while page <= max_pages:\n",
    "            payload = {\n",
    "                \"instrument_name\": pair,\n",
    "                \"from_timestamp\": ts_from,\n",
    "                \"to_timestamp\": ts_to,\n",
    "                \"instrument_type\": \"perp\",\n",
    "                \"page\": page,\n",
    "                \"page_size\": 1000,\n",
    "            }\n",
    "            try:\n",
    "                r = requests.post(API_URL, json=payload, timeout=10)\n",
    "                r.raise_for_status()\n",
    "                res = r.json().get(\"result\", {})\n",
    "                trades = res.get(\"trades\", []) if isinstance(res, dict) else res\n",
    "                if not trades:\n",
    "                    break\n",
    "                all_trades.extend(trades)\n",
    "                if len(trades) < 1000:\n",
    "                    break\n",
    "                page += 1\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                print(f\"Erreur API sur {pair} (page {page}) : {str(e)}\")\n",
    "                if error_count >= max_errors:\n",
    "                    print(f\"Abandon de la paire {pair} après {error_count} erreurs.\")\n",
    "                    break\n",
    "    return _prepare(pd.DataFrame(all_trades))\n",
    "\n",
    "\n",
    "\n",
    "def load_data(csv_files: List[str], pairs: List[str], ts_from: int, ts_to: int):\n",
    "    df_csv = pd.concat([pd.read_csv(p) for p in csv_files], ignore_index=True)\n",
    "    trade_ids = df_csv[df_csv.liquidity_role.str.lower()==\"maker\"].trade_id.unique()\n",
    "\n",
    "    df_api = fetch_trades_api(pairs, ts_from, ts_to)\n",
    "    if df_api.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "\n",
    "    df_api = df_api[df_api.trade_id.isin(trade_ids)]\n",
    "    return (\n",
    "        _prepare(df_api[df_api.liquidity_role.str.lower()==\"maker\"]),\n",
    "        _prepare(df_api[df_api.liquidity_role.str.lower()==\"taker\"]),\n",
    "    )\n",
    "\n",
    "###############################################################################\n",
    "# 4. ANALYSE D’UN PROGRAMME                                                 #\n",
    "###############################################################################\n",
    "\n",
    "def analyse_program(folder: str, mm_map: Dict[str, List[str]]):\n",
    "    parts = folder.split(\"_\")\n",
    "    if len(parts) != 3:\n",
    "        return None  # format inattendu\n",
    "    program_name, start_ts_str, end_ts_str = parts[0], parts[1], parts[2]\n",
    "    if program_name not in PAIRS_BY_PROGRAM:\n",
    "        return None  # ignore OPTIONS et inconnus\n",
    "\n",
    "    start_ts = int(start_ts_str)\n",
    "    key_mm = f\"{program_name}_{start_ts}\"\n",
    "    mm_list = mm_map.get(key_mm, [])\n",
    "\n",
    "    csv_folder = os.path.join(EXTRACTION_ROOT, folder)\n",
    "    if not os.path.isdir(csv_folder):\n",
    "        return None\n",
    "    csv_files = [os.path.join(csv_folder, f) for f in os.listdir(csv_folder) if f.endswith(\".csv\")]\n",
    "    if not csv_files:\n",
    "        return None\n",
    "\n",
    "    # Header programme\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    date_str = datetime.fromtimestamp(start_ts/1000).strftime(\"%Y-%m-%d\")\n",
    "    print(f\"PROGRAMME {program_name} | epoch {date_str} | CSV {len(csv_files)} | MM {len(mm_list)}\")\n",
    "    print(\"=\"*80)\n",
    "\n",
    "    df_maker, df_taker = load_data(csv_files, PAIRS_BY_PROGRAM[program_name], start_ts, int(end_ts_str))\n",
    "    if df_maker.empty or df_taker.empty:\n",
    "        print(\"  → aucune donnée exploitable (API ou CSV)\")\n",
    "        return None\n",
    "\n",
    "    G = build_graph(df_maker, df_taker, set(mm_list))\n",
    "    patterns = detect_patterns(G)\n",
    "\n",
    "    # Tableaux patterns ---------------------------------------------------\n",
    "    cycles = [p for p in patterns if p[\"type\"] == \"cycle\"]\n",
    "    bidis  = [p for p in patterns if p[\"type\"] == \"bidi\"]\n",
    "    ratios = [p for p in patterns if p[\"type\"] == \"ratio\"]\n",
    "\n",
    "    print_df(pd.DataFrame([\n",
    "        {\"ID\": i+1, \"Chemin\": \" -> \".join(p[\"addresses\"]) + \" -> \" + p[\"addresses\"][0], \"Volume\": p[\"volume\"], \"Trades\": len(p[\"trades\"])}\n",
    "        for i, p in enumerate(cycles)\n",
    "    ]).head(TOP_N_PATTERN), \"CYCLES COURTS\")\n",
    "\n",
    "    print_df(pd.DataFrame([\n",
    "        {\"ID\": i+1, \"Adresses\": \" <-> \".join(p[\"addresses\"]), \"Volume\": p[\"volume\"], \"Paires\": len(p[\"pairs\"])}\n",
    "        for i, p in enumerate(bidis)\n",
    "    ]).head(TOP_N_PATTERN), \"BIDIRECTIONNELS <1h\")\n",
    "\n",
    "    print_df(pd.DataFrame([\n",
    "        {\"ID\": i+1, \"Adresse\": p[\"address\"], \"Ratio\": f\"{p['ratio']:.2f}\", \"Voisins\": len(p[\"neighbors\"])}\n",
    "        for i, p in enumerate(ratios)\n",
    "    ]).head(TOP_N_PATTERN), \"ADRESSES RATIO>0.5\")\n",
    "\n",
    "    # Récap par adresse suspecte -----------------------------------------\n",
    "    addr_stats: Dict[str, dict] = defaultdict(lambda: {\"patterns\": 0, \"volume\": 0.0, \"cycles\": 0, \"bidis\": 0, \"ratios\": 0})\n",
    "    for p in patterns:\n",
    "        if p[\"type\"] == \"cycle\":\n",
    "            for a in p[\"addresses\"]:\n",
    "                s = addr_stats[a]; s[\"patterns\"] += 1; s[\"volume\"] += p[\"volume\"]; s[\"cycles\"] += 1\n",
    "        elif p[\"type\"] == \"bidi\":\n",
    "            for a in p[\"addresses\"]:\n",
    "                s = addr_stats[a]; s[\"patterns\"] += 1; s[\"volume\"] += p[\"volume\"]; s[\"bidis\"] += 1\n",
    "        else:\n",
    "            a = p[\"address\"]\n",
    "            s = addr_stats[a]; s[\"patterns\"] += 1; s[\"ratios\"] += 1\n",
    "\n",
    "    addr_df = pd.DataFrame([\n",
    "        {\"Adresse\": a, **stats} for a, stats in addr_stats.items()\n",
    "    ]).sort_values([\"patterns\", \"volume\"], ascending=False)\n",
    "\n",
    "    print_df(addr_df.head(TOP_N_ADDRESS), \"ADRESSES LES PLUS SUSPECTES\")\n",
    "\n",
    "    # Mini‑rapport par adresse (affichage détaillé)\n",
    "    for _, row in addr_df.head(TOP_N_ADDRESS).iterrows():\n",
    "        print(\"\\n\" + \"-\"*60)\n",
    "        print(f\"ADRESSE SUSPECTE : {row['Adresse']}\")\n",
    "        print(\"-\"*60)\n",
    "        print(f\"  • Patterns totaux     : {row['patterns']}\")\n",
    "        print(f\"  • Volume suspect      : ${row['volume']:,.2f}\")\n",
    "        print(f\"    – Cycles            : {row['cycles']}\")\n",
    "        print(f\"    – Bidirectionnels   : {row['bidis']}\")\n",
    "        print(f\"    – Ratios élevés     : {row['ratios']}\")\n",
    "\n",
    "    return {\n",
    "        \"program_name\": program_name,\n",
    "        \"date\": date_str,\n",
    "        \"patterns_count\": len(patterns),\n",
    "        \"cycles\": len(cycles),\n",
    "        \"bidis\": len(bidis),\n",
    "        \"ratios\": len(ratios),\n",
    "        \"total_volume\": sum(p.get(\"volume\", 0) for p in patterns),\n",
    "    }\n",
    "\n",
    "###############################################################################\n",
    "# 5. BOUCLE GLOBALE                                                          #\n",
    "###############################################################################\n",
    "\n",
    "def run_all_programs():\n",
    "    # Vérifier chemins\n",
    "    if not os.path.isdir(EXTRACTION_ROOT):\n",
    "        raise FileNotFoundError(f\"EXTRACTION_ROOT introuvable: {EXTRACTION_ROOT}\")\n",
    "    if not os.path.isfile(MM_JSON_PATH):\n",
    "        raise FileNotFoundError(f\"MM_JSON_PATH introuvable: {MM_JSON_PATH}\")\n",
    "\n",
    "    with open(MM_JSON_PATH, \"r\", encoding=\"utf-8\") as f:\n",
    "        mm_map = json.load(f)\n",
    "\n",
    "    folders = [d for d in os.listdir(EXTRACTION_ROOT) if os.path.isdir(os.path.join(EXTRACTION_ROOT, d))]\n",
    "    folders.sort()\n",
    "\n",
    "    global_results = []\n",
    "    for folder in folders:\n",
    "        res = analyse_program(folder, mm_map)\n",
    "        if res:\n",
    "            global_results.append(res)\n",
    "\n",
    "    # ------------------------------ Synthèse globale ---------------------------\n",
    "    if global_results:\n",
    "        total_prog = len(global_results)\n",
    "        tot_patterns = sum(r[\"patterns_count\"] for r in global_results)\n",
    "        tot_cycles   = sum(r[\"cycles\"] for r in global_results)\n",
    "        tot_bidis    = sum(r[\"bidis\"] for r in global_results)\n",
    "        tot_ratios   = sum(r[\"ratios\"] for r in global_results)\n",
    "        tot_volume   = sum(r[\"total_volume\"] for r in global_results)\n",
    "\n",
    "        top_prog = max(global_results, key=lambda r: r[\"patterns_count\"])[\"program_name\"] if global_results else None\n",
    "\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"SYNTHÈSE GLOBALE\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"Programmes analysés          : {total_prog}\")\n",
    "        print(f\"Patterns suspects (total)    : {tot_patterns}\")\n",
    "        print(f\"Volume total suspect         : ${tot_volume:,.2f}\")\n",
    "        print(\"Répartition des patterns     :\")\n",
    "        print(f\"  – Cycles                  : {tot_cycles}\")\n",
    "        print(f\"  – Bidirectionnels <1h     : {tot_bidis}\")\n",
    "        print(f\"  – Ratios élevés           : {tot_ratios}\")\n",
    "        if top_prog:\n",
    "            print(f\"\\nProgramme le plus problématique : {top_prog}\")\n",
    "\n",
    "        # Détail top 3\n",
    "        df_glob = pd.DataFrame(global_results)\n",
    "        df_top = df_glob.sort_values(\"patterns_count\", ascending=False).head(3)\n",
    "        if not df_top.empty:\n",
    "            print(\"\\nTop 3 programmes par patterns suspects :\")\n",
    "            for i, row in enumerate(df_top.itertuples(index=False), 1):\n",
    "                print(f\"{i}. {row.program_name} ({row.date}) – {row.patterns_count} patterns, volume ${row.total_volume:,.2f}\")\n",
    "\n",
    "        # Recommandations de base\n",
    "        print(\"\\nRECOMMANDATIONS :\")\n",
    "        recos = [\n",
    "            \"Inspecter manuellement les programmes avec >100 patterns et/ou volume élevé\",\n",
    "            \"Identifier si les adresses apparaissent dans plusieurs programmes\",\n",
    "            \"Surveiller en continu les cycles courts récurrents\",\n",
    "            \"Mettre en place seuils dynamiques sur ratio bidirectionnel\",\n",
    "            \"Réviser les conditions d'éligibilité des market-makers\",\n",
    "        ]\n",
    "        for i, txt in enumerate(recos, 1):\n",
    "            print(f\"{i}. {txt}\")\n",
    "\n",
    "        print(\"\\nATTENTION : ces heuristiques signalent des anomalies, pas des preuves. Une revue humaine reste indispensable.\")\n",
    "    else:\n",
    "        print(\"\\nAucun programme exploitable n'a été trouvé ou aucune donnée retour API.\")\n",
    "\n",
    "###############################################################################\n",
    "# 6. MAIN                                                                     #\n",
    "###############################################################################\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"ANALYSE DE WASH TRADING — VERSION CONSOLE SEULE\")\n",
    "    run_all_programs()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
